ANISHA ANIL

Abstract:
Person re-identification (Re-ID) aims at matching images of the sameperson across disjoint camera views, which is a challenging problem inmultimedia analysis, multimedia editing and content-based media retrievalcommunities. The major challenge lies in how to preserve similarity of thesame person across video footages with large appearance variations, whilediscriminating different individuals. To address this problem, conventionalmethods usually consider the pairwise similarity between persons by onlymeasuring the point to point (P2P) distance. Here the propose d techniqueuses deep learning to model a novel set to set (S2S) distance, in which theunderline objective focuses on preserving the compactness of intra-classsamples for each camera view, while maximizing the margin between theintra- class set and inter-class set. The S2S distance metric is consisted ofthree terms, namely the class-identity term, the relative distance term andthe regularization term. The class-identity term keeps the intra-classsamples within each camera view gathering together, the relative distanceterm maximizes the distance between the intra-class class set and inter-class set across different camera views, and the regularization termsmoothness the parameters of deep convolutional neural network (CNN).As a result, the final learned deep model can effectively find out thematched target to the probe object among various candidates in the videogallery by learning discriminative and stable feature representations. Usingthe CUHK01, CUHK03, PRID2011 and Market1501 benchmark datasets,extensive comparative evaluations are conducted to demonstrate theadvantages of this method over the state-of-the-art approaches.
